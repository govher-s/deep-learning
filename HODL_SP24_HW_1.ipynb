{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/govher-s/deep-learning/blob/main/HODL_SP24_HW_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfYu-Hk0R8PO"
      },
      "source": [
        "# 15.777 Homework 1 (Spring 2024): Convolutional Neural Networks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5kWWfR8z9uZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "\n",
        "# initialize the seeds of different random number generators so that the\n",
        "# results will be the same every time the notebook is run\n",
        "keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Please be sure to make a copy of this notebook in your own Google Drive so that your work is saved!** </font>"
      ],
      "metadata": {
        "id": "PFYMkD74Q3Tl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWOYqBF03aBE"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Your goal in this exercise is to detect emotion from a facial image. To that end, we will use the 2013 Facial Expression Recognition (FER) dataset.\n",
        "\n",
        "The dataset consists of ~36,000 images, each annotated with one of seven labels:\n",
        "* angry\n",
        "* disgust\n",
        "* fear\n",
        "* happy\n",
        "* sad\n",
        "* surprise\n",
        "* neutral\n",
        "\n",
        "The goal of this homework assignment is to walk you through how to:\n",
        "\n",
        "1. Build a Convolutional Neural Network (CNN) *from scratch* to detect emotion in facial images (Problems 1 and 2)\n",
        "2. Use data augmentation to increase the size of your training data (Problem 3)\n",
        "3. Use transfer learning to customize a pretrained model to solve the same problem (Problem 4)\n",
        "\n",
        "But first, let's get the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kklgssFnY8Ob"
      },
      "outputs": [],
      "source": [
        "!wget -q -O fer2013.csv -P ./ https://dl.dropbox.com/scl/fi/e2ik6aryemboameq1rwwn/fer2013.csv?rlkey=ux7tyge6flk9nnuul9desizgf&dl=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGMwyHWIZhGi"
      },
      "source": [
        "The data has 35887 rows and 3 columns:\n",
        "* Emotion - encoded as the numbers 0 (anger) through 6 (neutral)\n",
        "* Pixels - A space-separated list of numbers representing the pixels of this image.\n",
        "* Usage - No need to worry about this column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5S29hLu7djK"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('fer2013.csv')\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmam5zVrqLnp"
      },
      "source": [
        "The pixel values for each image is provided as a space-separated list of numbers. How many pixels in an image?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB5sxzlcqekw"
      },
      "outputs": [],
      "source": [
        "len(data.loc[0, 'pixels'].split(' '))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtEmyeIL7o9V"
      },
      "source": [
        "### Pre-Processing the Pixels (Independent Variable)\n",
        "\n",
        "Each image is encoded as a list of 2304 pixels. We will reshape this into an 48x48 image next.\n",
        "\n",
        "Recall that a color image is represented as a tensor of dimension N by M by 3, where the 3 represents the 3 color channels (red, green and blue). Our images from the FER 2013 dataset are grayscale images, with only a single channel representing the amount of black in the image. This is inconvenient to work with because many pre-trained models used in transfer learning, such as the one we will use in Problem 4, require the input image to have 3 channels.\n",
        "\n",
        "To get around this, we will take each image, a 48 x 48 tensor and transform it into a 48 x 48 x 3 tensor by simply duplicating it three times. We can think of a greyscale image is one where the red, green and blue color channels are exactly the same.\n",
        "\n",
        "The following code transforms our dataset into a tensor of shape (35887, 48, 48, 3): a list of 35887 images, each of which are a (48, 48, 3)-shape tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG4mAu4k-k86"
      },
      "outputs": [],
      "source": [
        "pixels = data['pixels'].tolist()\n",
        "width, height = 48, 48\n",
        "faces = []\n",
        "for pixel_sequence in pixels:\n",
        "    face = [int(pixel) for pixel in pixel_sequence.split(' ')] # read each face as a 1-d array\n",
        "    face = np.asarray(face).reshape(width, height) # reshape the length 2304 1-d array into an 48x48 array\n",
        "    face = np.stack((face,)*3, axis=-1)\n",
        "    faces.append(face.astype('float32'))\n",
        "\n",
        "faces = np.asarray(faces)\n",
        "faces.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the first image, i.e. `faces[0]`, we can examine its first channel (corresponding to \"red\")."
      ],
      "metadata": {
        "id": "likfKGSaJ0mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "faces[0, :, :, 0]"
      ],
      "metadata": {
        "id": "Eb5gYVXZHx1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the exact same as the second channel (corresponding to \"blue\"). And similarly for green."
      ],
      "metadata": {
        "id": "_2mKW0xZJ-HB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "faces[0, :, :, 1]"
      ],
      "metadata": {
        "id": "uCHDOZcqH9fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3rDhcpVrIVh"
      },
      "source": [
        "### Pre-Processing for Emotions (Dependent Variable)\n",
        "\n",
        "Next, let's take a look at how emotion (the dependent variable) is encoded. We have that 0 = 'angry', 1 = 'disgust', ... 6 = 'neutral'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMRxvh9grOBW"
      },
      "outputs": [],
      "source": [
        "data.emotion.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZb-BpG6rjpa"
      },
      "source": [
        "We will convert emotion to a one-hot encoding using the `pd.get_dummies` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O9Mj_fkrGig"
      },
      "outputs": [],
      "source": [
        "emotions = pd.get_dummies(data['emotion']).to_numpy() # each emotion is 'one-hot' encoded as a 7-dim vector\n",
        "emotions_names = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "emotions.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WZRh-dDBvWw"
      },
      "source": [
        "### Example Images\n",
        "Lets take a look at some of these fun images!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqmEpir1B3Mu"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    ax = fig.add_subplot(3, 3, i+1)\n",
        "    ax.set_title(f\"{emotions_names[np.argmax(emotions[i])]}\")\n",
        "    ax.imshow(faces[i].astype('uint8'))\n",
        "    ax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sts35VbQGJMf"
      },
      "source": [
        "### Train/Test Split\n",
        "As in the original dataset, we will reserve the first 28,709 images for training and the rest for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux8sgM1kptNb",
        "outputId": "aed1bb2d-4323-4d8e-e9e0-803b2cfc86b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((28709, 48, 48, 3), (28709, 7), (7178, 48, 48, 3), (7178, 7))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_faces, train_emotions =  faces[:28709], emotions[:28709]\n",
        "test_faces, test_emotions =  faces[28709:], emotions[28709:]\n",
        "\n",
        "train_faces.shape, train_emotions.shape, test_faces.shape, test_emotions.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aQhn5et0LoL"
      },
      "source": [
        "# Problem 1: Base Model [30 Points]\n",
        "In this problem, we will build a simple CNN with three convolutional blocks, one dense layer and one output layer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1XTkuqYivlI"
      },
      "source": [
        "\n",
        "## Part (a): Building the Model [10 points]\n",
        "We would like to build a CNN with the following model summary. Fill in the code in the cell below so that the output of `model.summary()` matches that of the image above. Be sure to use relu activation for each of the Conv2D layers and the appropriate activation function for the output layer.\n",
        "\n",
        "\n",
        "![](https://dl.dropbox.com/scl/fi/lrmaupoa243xrrsfj3qiy/cnn_model.PNG?rlkey=n5axqin6vx652qrgduyosg0pc&dl=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJD-ejmW0naX"
      },
      "outputs": [],
      "source": [
        "input = keras.Input(shape=(48, 48, 3), name=\"input\")\n",
        "\n",
        "###### YOUR CODE HERE #####\n",
        "\n",
        "\n",
        "###### YOUR CODE HERE #####\n",
        "\n",
        "model = keras.Model(input, output, name='CNN_model')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK3C_2eMckDm"
      },
      "source": [
        "## Part (b): Number of Parameters [10 points]\n",
        "The model above has $106,743$ trainable parameters and is computed by $208 + 1040 + 1040 + 102656 + 1799$. Explain how each of these 5 numbers is calculated and show your computations (e.g. 208 = 16 * 3 * 4 + 16).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>**Your Answer.**</font>\n",
        "\n",
        "_Please replace this text with your answer_"
      ],
      "metadata": {
        "id": "t7rlQY-Zt59w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdqxVs0kfDzP"
      },
      "source": [
        "## Part (c): Training and Evaluation [10 points]\n",
        "\n",
        "Let us compile our model and fit it on the training data. Since we one-hot-encoded the dependent variable, we use `categorical_crossentropy`, not `sparse_categorical_crossentropy`.\n",
        "\n",
        "Fill in the parameters of `model.compile` and `model.fit` below.\n",
        "\n",
        "* Compile the model using the `categorical_crossentropy` loss, `adam` optimizer and report the `accuracy` metric.\n",
        "* Fit the model on `train_faces`, `train_emotions` using a batch size of 64, for 30 epochs and a validation split of 20%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHAHKo0W1fym"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    ### YOUR CODE HERE ###\n",
        ")\n",
        "\n",
        "model_history = model.fit(\n",
        "    ### YOUR CODE HERE ###\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qsM4-N2f9rk"
      },
      "source": [
        "**Epochs and Batches.**\n",
        "\n",
        "In your own words, please explain the relationship between an epoch and a batch in stochastic gradient descent.\n",
        "\n",
        "<font color='red'>**Your Answer.**</font>\n",
        "\n",
        "_Please replace this text with your answer_\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "When we ran `model.fit`, we saw that there are 359 batches per epoch. Please explain how this 359 is calculated. _Hint_: There are 28,709 training data points and 20% is set aside for validation.\n",
        "\n",
        "<font color='red'>**Your Answer.**</font>\n",
        "\n",
        "_Please replace this text with your answer_\n"
      ],
      "metadata": {
        "id": "-2sSw5JCvQOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting the Training/Validation Accuracy Curve**\n",
        "\n",
        "Use the `plot_accuracy` function below to plot the training and validation accuracy across the training epochs."
      ],
      "metadata": {
        "id": "tDVnJpOUvTwI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YHzLOsNuwbE"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy(model_history):\n",
        "    history_dict = model_history.history\n",
        "    acc = history_dict[\"accuracy\"]\n",
        "    val_acc = history_dict[\"val_accuracy\"]\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "    plt.plot(epochs, acc, \"bo\", label=\"Training Accuracy\", linewidth=3)\n",
        "    plt.plot(epochs, val_acc, \"b\", label=\"Validation Accuracy\", linewidth=3)\n",
        "    plt.title(\"Training and Validation Accuracy Across Epochs\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_accuracy(model_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMHLB8_fuDbn"
      },
      "source": [
        "**Model Accuracy**\n",
        "\n",
        "Calculate the accuracy on the test set. Write your code below to show the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2S3SGwF1bXW"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAG5qQ7WXco0"
      },
      "source": [
        "# Problem 2: Wider and Deeper Models [30 Points]\n",
        "In this problem, we will modify the model from Problem 1 in two ways:\n",
        "* Increase the width of the model by adding more filters and more neurons in the dense layer.\n",
        "* Increase the depth of the model by adding another dense layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0jrlFUMjkdU"
      },
      "source": [
        "### Part (a): Wider Model [5 points]\n",
        "Take the `model` from Problem 1 and modify it into `wider_model` by using 32 filters for the convolution layers instead of 16.\n",
        "\n",
        "\n",
        "Write your new code below and verify that `wider_model.summary()` looks correct. Your model should have 215,527 parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzU_AhECXvfc"
      },
      "outputs": [],
      "source": [
        "input = keras.Input(shape=train_faces.shape[1:])\n",
        "\n",
        "### YOUR CODE BELOW ###\n",
        "\n",
        "\n",
        "### YOUR CODE ABOVE ###\n",
        "\n",
        "wider_model = keras.Model(input, output, name='wider_cnn')\n",
        "wider_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coJFUdBmkRyY"
      },
      "source": [
        "## Part (b): Number of Parameters [5 points]\n",
        "The model above has $215,527$ trainable parameters and is computed by $416 + 4128 + 4128 + 205056 + 1799$. Explain how each of these 5 numbers is calculated and show your computations.\n",
        "\n",
        "<font color='red'>**Your Answer.**</font>\n",
        "\n",
        "_Please replace this text with your answer_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiTnrJ8KkwC6"
      },
      "source": [
        "## Part (c): Training and Evaluation [5 points]\n",
        "Let's train our model and evaluate its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66cEA3fDYKGe"
      },
      "outputs": [],
      "source": [
        "wider_model.compile(\n",
        "    ### YOUR CODE HERE ###\n",
        ")\n",
        "\n",
        "wider_model_history = wider_model.fit(\n",
        "    ### YOUR CODE HERE ###\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0httpbJ7YMDP"
      },
      "outputs": [],
      "source": [
        "plot_accuracy(wider_model_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSE66SFUYQek"
      },
      "outputs": [],
      "source": [
        "# Calculate the test accuracy\n",
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the accuracy curve of `wider_model` to that of `model` from Problem 1. Which shows more evidence of overfitting after 30 epochs? Does that make sense?\n",
        "\n",
        "<font color='red'> **Your Answer.** </font>\n",
        "\n",
        "_Please replace this text with your answer_\n",
        "\n"
      ],
      "metadata": {
        "id": "k-wUFQbny1zQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-ET_tUVluUm"
      },
      "source": [
        "## Part (d): Deeper Model [5 Points]\n",
        "Now, build a new model called `deep_model` by taking `model` from Problem 1 and add an additional dense layer of 256 nodes immediately after the original dense layer of 256 nodes. The new model should have a total of 2 dense layers of 256 nodes each and have a total of 172,535 parameters.\n",
        "\n",
        "Train the model, plot its accuracy vs epochs using the `plot_accuracy` function, and report the model's accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7pLN2Ocm8wo"
      },
      "outputs": [],
      "source": [
        "input = keras.Input(shape=train_faces.shape[1:])\n",
        "\n",
        "### YOUR CODE BELOW ###\n",
        "\n",
        "\n",
        "### YOUR CODE ABOVE ###\n",
        "\n",
        "deeper_model = keras.Model(input, output, name='deeper_cnn')\n",
        "deeper_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Av-clYJnrfG"
      },
      "outputs": [],
      "source": [
        "deeper_model.compile(\n",
        "    ### YOUR CODE HERE ###\n",
        ")\n",
        "\n",
        "deeper_model_history = deeper_model.fit(\n",
        "    ### YOUR CODE HERE ###\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzZkN-mlnxgM"
      },
      "outputs": [],
      "source": [
        "plot_accuracy(deeper_model_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWZyzbPToSiQ"
      },
      "outputs": [],
      "source": [
        "# Calculate the test accuracy\n",
        "### YOUR CODE HERE ###\n",
        "deeper_model.evaluate(test_faces, test_emotions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdXmHlfbm9vv"
      },
      "source": [
        "## Part (e): Comparison [10 points]\n",
        "Comment on the difference between the test accuracy of `model`, `wider_model` and `deeper_model`. Did widening the model or deepening the model result in a better performance? Why? Do you think\n",
        "this result generally holds true for all problems?\n",
        "\n",
        "<font color='red'>**Your Answer**</font>\n",
        "\n",
        "Test Accuracy Comparison:\n",
        "* `model`: 0.00%\n",
        "* `wider_model`: 0.00%\n",
        "* `deeper_model`: 0.00%\n",
        "\n",
        "_Please fill in the numbers above and replace this text with your response._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIGCf1_zA5G1"
      },
      "source": [
        "# Problem 3: Data Augmentation [15 Points]\n",
        "\n",
        "The basic idea of augmentation is to alter the image so slightly that the value of the dependent variable (i.e. the category that it belongs to) doesn't change.\n",
        "\n",
        "Keras allows us to easily perform data augmentation using layers such as:\n",
        "\n",
        "* `keras.layers.RandomFlip`\n",
        "* `keras.layers.RandomZoom`\n",
        "* `keras.layers.RandomRotation`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ehLSXqP1b5P"
      },
      "source": [
        "Lets quickly visualize what the augmentation does ... Here, we flip the images horizontally, then apply a random zoom of up to 20%. Note that you do not need to understand how the code below works. Most of it is there to allow us to visualize the augmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTDMmESZ6TZ_"
      },
      "outputs": [],
      "source": [
        "def augment_images(image):\n",
        "    x = keras.layers.RandomFlip(\"horizontal\")(image)\n",
        "    x = keras.layers.RandomZoom(0.2)(x)\n",
        "    return x\n",
        "\n",
        "augmented_images = [augment_images(np.expand_dims(train_faces[0],axis=0)) for i in range(9)]\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    ax = fig.add_subplot(3, 3, i+1, xticks=[], yticks=[])\n",
        "    ax.imshow(tf.keras.preprocessing.image.array_to_img(augmented_images[i][0]), cmap='gray', vmin=0, vmax=255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "880VpBCxpEBj"
      },
      "source": [
        "We take our model `wider_model` from Problem 2(c) and add a random flip and random zoom as **layers** before the rescaling layer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = keras.Input(shape=(48, 48, 3))\n",
        "\n",
        "### DATA AUGMENTATION ###\n",
        "x = keras.layers.RandomFlip(\"horizontal\")(input)\n",
        "x = keras.layers.RandomZoom(0.2)(x)\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "# Please insert your code from wider_model here.\n",
        "\n",
        "model_augmented = keras.Model(input, output, name='augmented_CNN_model')\n",
        "model_augmented.summary()"
      ],
      "metadata": {
        "id": "NQne3K6XZ5iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of1CxdGirYlJ"
      },
      "source": [
        "Train the model (using the same parameters as all previous questions), show the accuracy vs. epoch curve, and report the accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJCy1tCyBhxb"
      },
      "outputs": [],
      "source": [
        "model_augmented.compile(\n",
        "    ### YOUR CODE HERE ###\n",
        ")\n",
        "\n",
        "model_augmented_history = model_augmented.fit(\n",
        "    ### YOUR CODE HERE ###\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhXMussbBqTQ"
      },
      "outputs": [],
      "source": [
        "plot_accuracy(model_augmented_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2narK55FJTXj"
      },
      "outputs": [],
      "source": [
        "# Calculate the test accuracy\n",
        "### YOUR CODE HERE ###\n",
        "deeper_model.evaluate(test_faces, test_emotions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Rcwg5ddbng"
      },
      "source": [
        "Compare this with `wider_model` and comment on the impact of data augmentation.\n",
        "\n",
        "* Did data augmentation reduce overfitting?\n",
        "* Did data augmentation improve test set accuracy\n",
        "\n",
        "<font color='red'> **Your Answer.** </font>\n",
        "\n",
        "_Please replace this text with your answer_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ddqer_8KbwB"
      },
      "source": [
        "# Problem 4: Transfer Learning and Fine-Tuning [25 points]\n",
        "\n",
        "Next, we apply transfer learning to our problem using VGG19, a pre-trained model similar to ResNet50 from class. We will take VGG19 and make it \"headless\", then run it through our own \"little\" NN.\n",
        "\n",
        "We will take three different approaches to this:\n",
        "\n",
        "1. Part (a): **Base Transfer Learning**. Fix the weights from headless VGG19 and learn the weights on the little NN.\n",
        "2. Part (b): **Some fine-tuning** Fix the weights on the top 6 out of 19 layers of VGG19, but allow the weights from the remaining 13 layers to be optimized by SGD/Adam, in addition to those of the little NN.\n",
        "3. Part (c): **Fine-Tuning** Allow all weights in VGG19 to be tuned, in addition to the little NN.\n",
        "\n",
        "For each of the models, we will plot their train/validation accuracy curve, compute their test accuracy, and compute a confusion matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHKqB9r1iH9W"
      },
      "source": [
        "## Part (a): No Fine Tuning [5 Points]\n",
        "\n",
        "Let us fetch the VGG19 model, making sure to set `include_top=False` so that we do not take its output layer. We also set `trainable=False` to indicate that the parameters in these 19 layers are not trainable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhkLJOKx0P67"
      },
      "outputs": [],
      "source": [
        "base_model = keras.applications.VGG19(\n",
        "    include_top=False,   # this makes VGG19 headless\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(48, 48, 3),\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "\n",
        "# Freeze the base_model so that it is not trainable at all\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vyZHcIZQcd9"
      },
      "source": [
        "We build a neural network that performs data augmentation and rescaling, then uses the VGG19, and finally has one dense layer before the output layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSdRDV--0fse"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(48,48,3))\n",
        "\n",
        "x = keras.layers.RandomFlip(\"horizontal\")(inputs)\n",
        "x = keras.layers.RandomZoom(0.2)(x)\n",
        "x = keras.layers.Rescaling(1./255)(x) # normalizing\n",
        "\n",
        "# Add layers from base_model one at a time\n",
        "for layer in base_model.layers:\n",
        "    x = layer(x)\n",
        "\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(256, activation='relu')(x)\n",
        "outputs = keras.layers.Dense(7, activation='softmax')(x)\n",
        "\n",
        "transfer_model = keras.Model(inputs, outputs, name='transfer_model')\n",
        "transfer_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G6oAxyD269z"
      },
      "source": [
        "Train the model. Here, we use a learning rate of 0.00002 to get better convergence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYOu-5lMPZRX"
      },
      "outputs": [],
      "source": [
        "transfer_model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=keras.optimizers.Adam(2e-5),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "transfer_model_history = transfer_model.fit(train_faces, train_emotions, epochs=30, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB071mHGZS32"
      },
      "source": [
        "We can plot the training and validation accuracy curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPZm77-w5phD"
      },
      "outputs": [],
      "source": [
        "plot_accuracy(transfer_model_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OlMcWW6ji1Z"
      },
      "source": [
        "Let's also calculate the confusion matrix and the accuracy on the test set.\n",
        "\n",
        "The function `show_confusion_matrix` has been written for you below. You can apply it to any Keras Model and it will calculate:\n",
        "* Test accuracy\n",
        "* A confusion matrix. Recall that each row of the confusion matrix are the actual labels and each column are the predictions. For example, if element in row `happy` and column `sad` is 250, then there are 250 data points in the test set where the true label is `happy` but we predicted `sad`.\n",
        "* A heatmap of the confusion matrix, where each row is normalized to add up to 1.0. For example, if element in row `happy` and column `sad` is 0.25, then that means 25% of data points with a true label of `happy` were predicted as `sad`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzg5PNAf1BiX"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "def show_confusion_matrix(model):\n",
        "    \"\"\"\n",
        "    Calculates the test accuracy, confusion matrix and heat map for a model.\n",
        "    \"\"\"\n",
        "    global test_faces, test_emotions, emotions_names\n",
        "\n",
        "    y_pred = model.predict(test_faces).argmax(axis=1)\n",
        "    y_actual = test_emotions.argmax(axis=1)\n",
        "\n",
        "    print('*************************\\n* Test Accuracy: %.4f *\\n*************************' % metrics.accuracy_score(y_actual, y_pred))\n",
        "\n",
        "    cm = pd.DataFrame(metrics.confusion_matrix(y_actual, y_pred), index=emotions_names, columns=emotions_names)\n",
        "    display(cm)\n",
        "\n",
        "    cm = cm.div(cm.sum(axis=1), axis=0)\n",
        "\n",
        "    sns.heatmap(cm, cmap=\"Blues\", annot=True, fmt=\".2f\")\n",
        "\n",
        "show_confusion_matrix(transfer_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please comment briefly on the model's performance."
      ],
      "metadata": {
        "id": "wDOxWtCg4kdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Your Answer** </font>\n",
        "\n",
        "_Please replace this text with your answer_"
      ],
      "metadata": {
        "id": "v-VgmSmN41tV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0PnqEU6ey9q"
      },
      "source": [
        "## Part (b): Some Fine Tuning [5 Points]\n",
        "In this part, we will allow our optimization model to tune **some** of the layers from VGG19. In particular, we will only freeze the first 15 layers and allow the remaining layers to be trained.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Su-u9FMPn-R"
      },
      "outputs": [],
      "source": [
        "base_model = keras.applications.VGG19(\n",
        "    include_top=False,   # this makes VGG19 headless\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "\n",
        "inputs = keras.Input(shape=(48,48,3))\n",
        "\n",
        "x = keras.layers.RandomFlip(\"horizontal\")(inputs)\n",
        "x = keras.layers.RandomZoom(0.2)(x)\n",
        "x = keras.layers.Rescaling(1./255)(x) # normalizing\n",
        "\n",
        "# Add layers from base_model\n",
        "for layer in base_model.layers:\n",
        "    x = layer(x)\n",
        "\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(256, activation='relu')(x)\n",
        "outputs = keras.layers.Dense(7, activation='softmax')(x)\n",
        "\n",
        "partial_model = keras.Model(inputs, outputs, name='partial_fine_tune_model')\n",
        "\n",
        "# Make the first 15 layers not trainable. All other layers are trainable\n",
        "for layer in partial_model.layers[:15]:\n",
        "    layer.trainable = False\n",
        "\n",
        "partial_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rvpaAcgie20"
      },
      "source": [
        "Let's see which layers are trainable. Notice that VGG19 consists of 4 blocks of convolution filters (block1_conv1, block1_conv2, ..., block5_conv4). We are allowing block4 and block5 to be trained and freezing blocks 1, 2 and 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB-D_9n-idOC"
      },
      "outputs": [],
      "source": [
        "for i, layer in enumerate(partial_model.layers):\n",
        "    print('Layer %d: %s (%s), Trainable=%s' % (i+1, layer.name, layer.__class__.__name__, layer.trainable))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYkyOqTgl2oT"
      },
      "source": [
        "Train the model and examine its train/validation curve, test accuracy and confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgxvrfuNVISF"
      },
      "outputs": [],
      "source": [
        "partial_model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=keras.optimizers.Adam(2e-5),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "partial_model_history = partial_model.fit(train_faces, train_emotions, epochs=30, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1W3a8u68GVo"
      },
      "outputs": [],
      "source": [
        "plot_accuracy(partial_model_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aHxeB2w85LM"
      },
      "outputs": [],
      "source": [
        "show_confusion_matrix(partial_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please comment briefly on the model's performance.  \n",
        "\n",
        "<font color='red'> **Your Answer** </font>\n",
        "\n",
        "_Please replace this text with your answer_"
      ],
      "metadata": {
        "id": "TRP-QrnN5je6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSbYpXZlhcFo"
      },
      "source": [
        "## Part (c): Fine Tuning [5 Points]\n",
        "Now, let's try a transfer learning model where all layers can be fine tuned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi7xZqzHhWFk"
      },
      "outputs": [],
      "source": [
        "base_model = keras.applications.VGG19(\n",
        "    include_top=False,   # this makes VGG19 headless\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "\n",
        "inputs = keras.Input(shape=(48,48,3))\n",
        "\n",
        "x = keras.layers.RandomFlip(\"horizontal\")(inputs)\n",
        "x = keras.layers.RandomZoom(0.2)(x)\n",
        "x = keras.layers.Rescaling(1./255)(x) # normalizing\n",
        "\n",
        "# Add layers from base_model\n",
        "for layer in base_model.layers:\n",
        "    x = layer(x)\n",
        "\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(256, activation='relu')(x)\n",
        "outputs = keras.layers.Dense(7, activation='softmax')(x)\n",
        "\n",
        "tuned_model = keras.Model(inputs, outputs, name='full_fine_tune_model')\n",
        "\n",
        "# Let's see which layers are trainable\n",
        "for i, layer in enumerate(tuned_model.layers):\n",
        "    print('Layer %d: %s (%s), Trainable=%s' % (i+1, layer.name, layer.__class__.__name__, layer.trainable))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j07Q_uF3hNNb"
      },
      "outputs": [],
      "source": [
        "tuned_model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=keras.optimizers.Adam(2e-5),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "tuned_model_history = tuned_model.fit(train_faces, train_emotions, epochs=30, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvA16HdjiDj0"
      },
      "outputs": [],
      "source": [
        "plot_accuracy(tuned_model_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OrcI__XjIIw"
      },
      "outputs": [],
      "source": [
        "show_confusion_matrix(tuned_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please comment briefly on the model's performance.  \n",
        "\n",
        "<font color='red'> **Your Answer** </font>\n",
        "\n",
        "_Please replace this text with your answer_"
      ],
      "metadata": {
        "id": "V8VUGegk6LrV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3fiasKHjYFI"
      },
      "source": [
        "## Part (d): Comparison [10 Points]\n",
        "\n",
        "Please fill in the table below with the test accuracies of the three models above, as well as that of `wider_model` from Problem 2.\n",
        "\n",
        "<font color='red'>**Your Answer.**</font>\n",
        "\n",
        "Model Test Accuracy:\n",
        "* Model (a) with no fine tuning: 0.00%\n",
        "* Model (b) with some fine tuning: 0.00%\n",
        "* Model (c) with fine tuning: 0.00%\n",
        "* `wider_model` from Problem 2(a)-(c): 0.00%"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Comment on the performance of Models (a), (b) and (c). In particular, please address the following questions:\n",
        "\n",
        "* Why do models (b) and (c) perform so much better than `wider_model`?\n",
        "* Why do you think Model (a) performs so poorly?\n",
        "* Why do you think Model (c) performs better than model (b)?\n",
        "\n",
        "<font color='red'>**Your Answer.**</font>\n",
        "\n",
        "_Please replace this text with your answer_"
      ],
      "metadata": {
        "id": "yTErUERP-fVr"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}